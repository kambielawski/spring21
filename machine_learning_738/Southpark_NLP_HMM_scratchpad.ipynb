{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blind-binary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Character</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle</td>\n",
       "      <td>Going away? For how long?\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Forever.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Chef</td>\n",
       "      <td>I'm sorry boys.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Stan</td>\n",
       "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Season Episode Character                                               Line\n",
       "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
       "1     10       1      Kyle                        Going away? For how long?\\n\n",
       "2     10       1      Stan                                         Forever.\\n\n",
       "3     10       1      Chef                                  I'm sorry boys.\\n\n",
       "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./SouthParkData-master/All-seasons.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "physical-prisoner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chef said he's been bored, so he joining a group called the Super Adventure Club. \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['Line'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-magazine",
   "metadata": {},
   "source": [
    "## We're going to attempt to implement the Viterbi algorithm\n",
    "\n",
    "### Here's what we need:\n",
    "\n",
    "#### parameters:\n",
    "\n",
    "K => number of hidden states\n",
    "\n",
    "T => length of sequence of observations\n",
    "\n",
    "N => number of possible observations \n",
    "\n",
    "S => the \"state space\", i.e. all possible words (s1, s2, ... , sK)\n",
    "\n",
    "Priors => an array of prior probabilities for each state (ie. how likely is a word to occur w/o context?)\n",
    "\n",
    "Transition Matrix A => K x K matrix where A[i, j] stores probability of transitioning from si to sj\n",
    "\n",
    "Emission Matrix   B => K x N matrix where B[i, j] stores probability of observing oj from state si\n",
    "    \n",
    "#### output:\n",
    "\n",
    "X - a sequence of states (x1, x2, ..., xT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-christopher",
   "metadata": {},
   "source": [
    "Let's first see how large of a vocabulary we're working with\n",
    "\n",
    "I'm going to include all individual words, plus some basic punctuation like ',' '.' '!' and '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "functional-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chef', 'said', \"he's\", 'been', 'bored', ',', 'so', 'he', 'joining', 'a', 'group', 'called', 'the', 'super', 'adventure', 'club', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# Takes a string, tokenizes it \n",
    "# Returns a list of the tokens\n",
    "def tokenize_str(string):\n",
    "    \n",
    "    string = string.lower()\n",
    "    \n",
    "    # give space on either side of punctuation\n",
    "    string = string.replace(',', ' ,')\n",
    "    string = string.replace('.', ' .')\n",
    "    string = string.replace('!', ' !')\n",
    "    string = string.replace('?', ' ?')\n",
    "    \n",
    "    # split string and add newline at end\n",
    "    string = string.split()\n",
    "    string += ['\\n']\n",
    "    \n",
    "    return string\n",
    "\n",
    "print(tokenize_str(raw_data['Line'][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "champion-truck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32834\n"
     ]
    }
   ],
   "source": [
    "# line_lists = [simplify_str(s).split() for s in raw_data['Line']]\n",
    "tokens = [word for sentence in raw_data['Line'] for word in tokenize_str(sentence)]\n",
    "\n",
    "states = set(tokens)\n",
    "vocab_size = len(states)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-bridal",
   "metadata": {},
   "source": [
    "32834 words is a lot to work with, but it might work. We may have to reduce dimensionality at some point.\n",
    "\n",
    "Since we're trying to generate text from this corpus, our # of observations N will be the same as K (vocab_size)\n",
    "\n",
    "Now we have our states, and also our # of states K, and our # of observations N. In our application, K == N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still need the transition matrix A and our emission matrix B \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_hmm",
   "language": "python",
   "name": "nlp_hmm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
